{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9as+PMpEig+Mzcz4fmBN2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Modelo para distinguir entre tipos de animales"
      ],
      "metadata": {
        "id": "FPpZAFgMoq1E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "110aFujKn_tO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import timm\n",
        "\n",
        "import matplotlib.pyplot as plt # For data viz\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "dataset_path = kagglehub.dataset_download(\"alessiocorrado99/animals10\")\n",
        "dataset_path = dataset_path + '/raw-img'\n",
        "\n",
        "print(\"Path to dataset files:\", dataset_path)\n",
        "\n",
        "print('System Version:', sys.version)\n",
        "print('PyTorch version', torch.__version__)\n",
        "print('Torchvision version', torchvision.__version__)\n",
        "print('Numpy version', np.__version__)\n",
        "print('Pandas version', pd.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creamos Clase del dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "py-GPm_ko7aR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AnimalDataset(Dataset):\n",
        "  def __init__(self, data_dir, transform=None):\n",
        "    self.data = ImageFolder(data_dir, transform=transform)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx]\n",
        "\n",
        "  @property\n",
        "  def classes(self):\n",
        "    return self.data.classes"
      ],
      "metadata": {
        "id": "ZLt6yHzIpDJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = AnimalDataset(data_dir=dataset_path)"
      ],
      "metadata": {
        "id": "dtzdunnlp7mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.classes)"
      ],
      "metadata": {
        "id": "DWd4npHFq1Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creamos dataloader"
      ],
      "metadata": {
        "id": "_Drtju5jswpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "suDHcfGdsyfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creamos modelo"
      ],
      "metadata": {
        "id": "Bxl6ROQwtB42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleAnimalClassifer(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleAnimalClassifer, self).__init__()\n",
        "        # Where we define all the parts of the model\n",
        "        self.base_model = timm.create_model('efficientnet_b0', pretrained=True)\n",
        "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
        "\n",
        "        enet_out_size = 1280\n",
        "        # Make a classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(enet_out_size, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Connect these parts and return the output\n",
        "        x = self.features(x)\n",
        "        output = self.classifier(x)\n",
        "        return output\n",
        "\n"
      ],
      "metadata": {
        "id": "EuKFlYS9tFoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleAnimalClassifer(num_classes=10)\n",
        "print(str(model)[:500])"
      ],
      "metadata": {
        "id": "Z9Nye_I1vMxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "Declare datasets and dataloaders"
      ],
      "metadata": {
        "id": "pfbk720QC4ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = AnimalDataset(dataset_path, transform)\n",
        "\n",
        "# Split: 80% train, 20% val\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "SRa_WFmSC4Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ],
      "metadata": {
        "id": "HN6pxyshJFnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "model = SimpleAnimalClassifer()\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc='Training loop'):\n",
        "        # Move inputs and labels to the device\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * labels.size(0)\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc='Validation loop'):\n",
        "            # Move inputs and labels to the device\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * labels.size(0)\n",
        "    val_loss = running_loss / len(val_loader.dataset)\n",
        "    val_losses.append(val_loss)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_loss}, Validation loss: {val_loss}\")"
      ],
      "metadata": {
        "id": "VvNerxQbJFGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Probar Modelo"
      ],
      "metadata": {
        "id": "2IgiYAegPwtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess the image\n",
        "def preprocess_image(image_path, transform):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    return image, transform(image).unsqueeze(0)\n",
        "\n",
        "# Predict using the model\n",
        "def predict(model, image_tensor, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        image_tensor = image_tensor.to(device)\n",
        "        outputs = model(image_tensor)\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "    return probabilities.cpu().numpy().flatten()\n",
        "\n",
        "# Visualization\n",
        "def visualize_predictions(original_image, probabilities, class_names):\n",
        "    fig, axarr = plt.subplots(1, 2, figsize=(14, 7))\n",
        "\n",
        "    # Display image\n",
        "    axarr[0].imshow(original_image)\n",
        "    axarr[0].axis(\"off\")\n",
        "\n",
        "    # Display predictions\n",
        "    axarr[1].barh(class_names, probabilities)\n",
        "    axarr[1].set_xlabel(\"Probability\")\n",
        "    axarr[1].set_title(\"Class Predictions\")\n",
        "    axarr[1].set_xlim(0, 1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "test_image = \"/content/caballo.jpg\"\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "original_image, image_tensor = preprocess_image(test_image, transform)\n",
        "probabilities = predict(model, image_tensor, device)\n",
        "\n",
        "# Assuming dataset.classes gives the class names\n",
        "class_names = dataset.classes\n",
        "visualize_predictions(original_image, probabilities, class_names)"
      ],
      "metadata": {
        "id": "In5SVVwQPyK-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}